{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/low_level/ingestion.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup  \n",
    "We build an empty Pinecone Index, and define the necessary LlamaIndex wrappers/abstractions so that we can start loading data into Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('env/pinecone.conf')\n",
    "\n",
    "api_key = config[\"DEFAULT\"][\"PINECONE_API_KEY\"]\n",
    "environment = config[\"DEFAULT\"][\"PINECONE_ENVIRONMENT\"]\n",
    "openai_api_key = config[\"DEFAULT\"][\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"llamaindex-rag-fs\"\n",
    "\n",
    "pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name, \n",
    "    dimension=1536, \n",
    "    metric=\"cosine\", \n",
    "    spec=PodSpec(environment=environment, pod_type=\"p1.x1\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Ingestion Pipeline from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "--2024-02-20 21:39:12--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "arxiv.org (arxiv.org) 해석 중... 151.101.195.42, 151.101.3.42, 151.101.67.42, ...\n",
      "다음으로 연결 중: arxiv.org (arxiv.org)|151.101.195.42|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 13661300 (13M) [application/pdf]\n",
      "저장 위치: `data/llama2.pdf'\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  6.47MB/s    /  2.0s    \n",
      "\n",
      "2024-02-20 21:39:14 (6.47 MB/s) - `data/llama2.pdf' 저장함 [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz     # pdf 정보 추출 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/llama2.pdf\"\n",
    "doc = fitz.open(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use a Text Splitter to Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1536,\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "# maintain relationship with source doc index, to help inject doc metadata in (3)\n",
    "doc_idxs = []\n",
    "for doc_idx, page in enumerate(doc):\n",
    "    page_text = page.get_text(\"text\")\n",
    "    cur_text_chunks = text_parser.split_text(page_text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Manually Construct Nodes from Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc_idx = doc_idxs[idx]\n",
    "    src_page = doc[src_doc_idx]\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗\n",
      "Louis Martin†\n",
      "Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov\n",
      "Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "our human evaluations for helpfulness and safety, may be a suitable substitute for closed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.\n",
      "∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.\n",
      "arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].metadata)\n",
    "# print a sample node\n",
    "print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom llama_index.core.extractors import (\\n    QuestionsAnsweredExtractor,\\n    TitleExtractor,\\n)\\nfrom llama_index.core.ingestion import IngestionPipeline\\nfrom llama_index.llms.openai import OpenAI\\n\\nllm = OpenAI(model=\"gpt-3.5-turbo\")\\n\\nextractors = [\\n    TitleExtractor(nodes=5, llm=llm),\\n    QuestionsAnsweredExtractor(questions=3, llm=llm),\\n]\\npipeline = IngestionPipeline(\\n    transformations=extractors,\\n)\\nnodes = await pipeline.arun(nodes=nodes, in_place=False)\\nprint(nodes[0].metadata)\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Optional] 4. Extract Metadata from each Node\n",
    "'''\n",
    "from llama_index.core.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    ")\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "extractors = [\n",
    "    TitleExtractor(nodes=5, llm=llm),\n",
    "    QuestionsAnsweredExtractor(questions=3, llm=llm),\n",
    "]\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=extractors,\n",
    ")\n",
    "nodes = await pipeline.arun(nodes=nodes, in_place=False)\n",
    "print(nodes[0].metadata)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Generate Embeddings for each Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load Nodes into a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 80/80 [00:01<00:00, 60.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['59b4f167-424f-4970-aa11-726d0dff6c45',\n",
       " '54499387-c80b-4ed1-a6c8-573233e8a544',\n",
       " 'd8c3f86d-a2b6-45ec-8223-8a2e120263bd',\n",
       " '81153352-1397-4697-84a4-e7bf9719f89b',\n",
       " '2aa56b9b-bb5c-4e39-91e6-3f685bbf50f5',\n",
       " 'd7204148-ce5d-4bf5-983d-b1bb8bd9ebd2',\n",
       " '892b9f94-396a-47f8-84e7-935e79f3121b',\n",
       " '88e80ade-3445-45c7-963f-af11c1d18150',\n",
       " '5da05f09-4817-49e6-8c67-6a9b250b4989',\n",
       " 'bb505547-7268-49b3-a626-962990a98959',\n",
       " 'f074068a-5b5a-4632-9e6b-ce71f34d2aec',\n",
       " '079b9d17-7af4-41e2-ad92-b8da83cba50e',\n",
       " '1a5a3510-91e2-44b9-b599-c62b5a9935ec',\n",
       " 'e85d1463-a79f-4b7b-8c7d-d126e03578a0',\n",
       " '7d324b3d-e9ec-4af8-afaa-a2ce2e8e090c',\n",
       " 'b2cb59e5-1078-442d-9ca4-a4b26c30d67c',\n",
       " 'a87ea862-8b4e-4447-9de5-fb9f173bc409',\n",
       " '39bce592-6a7f-4735-a531-0a42cba85ded',\n",
       " 'b6e74359-88fa-44bd-be0b-91434c73446e',\n",
       " '70ed1c78-03d5-4b44-a6af-a5643e2f35e3',\n",
       " 'a4ef88eb-3e70-4a31-8e3a-3b4059408e91',\n",
       " '9b11e808-35a2-4090-8520-eb75d1021d1b',\n",
       " '31fb3ce2-a80c-4a5a-8f73-cebf67662714',\n",
       " 'ef7ad5b8-dcd6-4e10-aa33-787286d4e1e6',\n",
       " 'f21afd6b-9d29-4972-b97d-18b05bd0e1b2',\n",
       " '0f4f9066-25cd-4719-b62b-0c4ac9c6f499',\n",
       " '4d31e52a-9e49-4b1f-b6cb-b78414da97b8',\n",
       " 'e66ebe63-8f5d-436f-a99a-7991346b4c24',\n",
       " '50a727a3-43a4-4d1f-a23b-43de97125e06',\n",
       " '95ad7733-fa20-4e6f-a103-337507c2d977',\n",
       " '930d305a-d495-4802-a75f-58cc81765e2a',\n",
       " '97f3c11d-2934-438c-ae8b-d523b1749031',\n",
       " '8a0f5f56-d8ce-4d12-b5c4-f9c379aaa694',\n",
       " '95a10736-5209-45a1-9bea-3cc1d7360959',\n",
       " '959ded18-3b98-4f0f-9775-5a06d118ff28',\n",
       " 'e15ab52e-f149-45d4-969b-02be0ba83c6f',\n",
       " '976ffd0f-c75d-49bf-855a-579fa4d65aa3',\n",
       " '03f713e6-6573-4afd-add2-5520e7ebf8ae',\n",
       " '75b8a9d2-0959-4518-b6b4-3fbffa15b452',\n",
       " '69ae60b7-46f4-4b3e-9522-2af8f0d53b3a',\n",
       " '686dbbbb-3d8e-4ad8-868c-718314a76133',\n",
       " '4084bbc5-ae42-4ae2-99b5-ae6664577f69',\n",
       " '40f7864c-72c2-42bc-aa37-acda35fc0c7b',\n",
       " 'b3dc1f1a-a488-4d6e-962d-024a01b74242',\n",
       " '28019b71-e9f4-4dae-92ad-a714d1d3b822',\n",
       " 'bc435cb4-94a7-4304-83b0-b3bb9de15245',\n",
       " '519e87a4-5b80-451b-9742-f17e2a0c9fa3',\n",
       " '8251424b-99d8-4874-9a15-e593cb552e9b',\n",
       " 'b7875345-99d8-4c9f-a040-ef98b00877ac',\n",
       " '29e7cf2a-7d21-4d77-a561-bc8ef8db34c0',\n",
       " '55896e3d-afac-45fb-834d-b34828bd3ae4',\n",
       " '016bf4da-658e-4f8a-9319-a15eaa997ad8',\n",
       " 'fa2d0f52-47e8-42f9-a55c-adbc6d940860',\n",
       " 'c2f6c7ae-3b95-4d01-b02d-06a052c6a85c',\n",
       " '3299da3a-d955-4944-b5c2-42a1edb9c73c',\n",
       " '8f8b2b51-c8aa-424c-bf9d-3d41eb669397',\n",
       " 'ccb664b8-dc06-4ee5-be78-e024312b4162',\n",
       " '5d4a0f49-cca0-4e69-8487-9c64621f5f92',\n",
       " 'aac14759-d7dd-4879-a265-324af27b4204',\n",
       " '3f2c4513-f1bf-4020-bea0-6d38e6525ae4',\n",
       " '66e74233-15d8-4596-a6fc-59891f072bc3',\n",
       " 'f022625d-7b5a-4302-9dc5-305e14ed8446',\n",
       " 'b5d8a31d-8ce6-4756-8246-1f4a4aec2df4',\n",
       " '1e716faa-b070-49c8-828c-bb75c7d9fa62',\n",
       " '2ee2ef97-b027-42ae-bd72-bb84f77f47b7',\n",
       " 'ba93afd6-754c-4c59-a10b-fd1279da84ef',\n",
       " 'a70d504c-7770-4e25-893f-e00d3135e099',\n",
       " 'd0f32a65-d9c0-4b76-a528-6f9a8a2119bb',\n",
       " 'bdccd795-4525-4ca9-9d9b-5e71ef17772e',\n",
       " '68542e68-e4d2-45d6-bdd2-a46e98bb3a0a',\n",
       " '6635ecb5-63f2-4567-8023-409fcd94c949',\n",
       " 'fa888621-b80c-4485-a079-35964d167db6',\n",
       " '626dbc4c-8429-481b-b817-736fe4557390',\n",
       " '4c7e0754-f810-4ae7-b533-c217edda3f5a',\n",
       " 'e4572b8c-7d76-42f5-8bec-9090e88e720b',\n",
       " 'b5e61876-79ae-4e06-a9a3-0317caa96fdb',\n",
       " 'b4df56a8-5cf6-4609-a777-8015415fe44c',\n",
       " '004aca7f-6660-4e17-88f5-58491e8dd2a4',\n",
       " 'ef423c5a-cae1-487b-9715-f90f7dc08871',\n",
       " '9aa53c67-d4a9-4fd5-98e6-39ceb16075e7']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now insert these nodes into our PineconeVectorStore.\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Query from the Vector Store\n",
    "Now that our ingestion is complete, we can retrieve/query this vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key concepts for safety fine-tuning include supervised safety fine-tuning, safety RLHF (Rejection Learning from Human Feedback), and safety context distillation. Supervised safety fine-tuning involves gathering adversarial prompts and safe demonstrations to align the model with safety guidelines. Safety RLHF integrates safety into the RLHF pipeline by training a safety-specific reward model and using challenging adversarial prompts for optimization. Safety context distillation refines the RLHF pipeline by generating safer model responses with safety preprompts and fine-tuning the model on these responses to distill the safety context into the model.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
